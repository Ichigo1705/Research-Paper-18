{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Jubin\\Desktop\\RP18\\Datasets\\intel\\interpolated\\injected_malfunction\\mote=1_sensortype=temperature_faulttype=malfunction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['timestamp', 'mote_id', 'light', 'has_fault_type'])\n",
    "Y = data['has_fault_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X_scaled, Y_encoded, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet denoising\n",
    "def wavelet_denoise(data):\n",
    "    denoised_data = []\n",
    "    for row in data:\n",
    "        coeffs = pywt.wavedec(row, 'db4', level=3)  # Adjust the wavelet and level as needed\n",
    "        thresholded_coeffs = [pywt.threshold(detail, 0.5, mode='soft') for detail in coeffs[1:]]\n",
    "        denoised_signal = pywt.waverec([coeffs[0]] + thresholded_coeffs, 'db4')  # Adjust the wavelet as needed\n",
    "        denoised_data.append(denoised_signal)\n",
    "    return np.array(denoised_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jubin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pywt\\_multilevel.py:45: UserWarning: Level value of 3 is too high: all coefficients will experience boundary effects.\n",
      "  \"boundary effects.\").format(level))\n"
     ]
    }
   ],
   "source": [
    "X_train_denoised = wavelet_denoise(X_train)\n",
    "X_val_denoised = wavelet_denoise(X_val)\n",
    "X_test_denoised = wavelet_denoise(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jubin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_denoised.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # For binary classification, adjust for multi-class\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/441 [===========================>..] - ETA: 0s - loss: 0.4869 - accuracy: 0.8172\n",
      "Epoch 1: val_loss improved from inf to 0.46379, saving model to best_model.h5\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4856 - accuracy: 0.8171 - val_loss: 0.4638 - val_accuracy: 0.8181\n",
      "Epoch 2/100\n",
      "400/441 [==========================>...] - ETA: 0s - loss: 0.4641 - accuracy: 0.8212\n",
      "Epoch 2: val_loss improved from 0.46379 to 0.45388, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8202 - val_loss: 0.4539 - val_accuracy: 0.8228\n",
      "Epoch 3/100\n",
      "407/441 [==========================>...] - ETA: 0s - loss: 0.4579 - accuracy: 0.8213\n",
      "Epoch 3: val_loss did not improve from 0.45388\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.8236 - val_loss: 0.4548 - val_accuracy: 0.8228\n",
      "Epoch 4/100\n",
      "389/441 [=========================>....] - ETA: 0s - loss: 0.4471 - accuracy: 0.8266\n",
      "Epoch 4: val_loss improved from 0.45388 to 0.44314, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8265 - val_loss: 0.4431 - val_accuracy: 0.8277\n",
      "Epoch 5/100\n",
      "419/441 [===========================>..] - ETA: 0s - loss: 0.4462 - accuracy: 0.8270\n",
      "Epoch 5: val_loss improved from 0.44314 to 0.44246, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8277 - val_loss: 0.4425 - val_accuracy: 0.8274\n",
      "Epoch 6/100\n",
      "421/441 [===========================>..] - ETA: 0s - loss: 0.4428 - accuracy: 0.8284\n",
      "Epoch 6: val_loss improved from 0.44246 to 0.43771, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8280 - val_loss: 0.4377 - val_accuracy: 0.8307\n",
      "Epoch 7/100\n",
      "422/441 [===========================>..] - ETA: 0s - loss: 0.4425 - accuracy: 0.8286\n",
      "Epoch 7: val_loss improved from 0.43771 to 0.43712, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.8284 - val_loss: 0.4371 - val_accuracy: 0.8313\n",
      "Epoch 8/100\n",
      "387/441 [=========================>....] - ETA: 0s - loss: 0.4437 - accuracy: 0.8274\n",
      "Epoch 8: val_loss improved from 0.43712 to 0.43553, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.8299 - val_loss: 0.4355 - val_accuracy: 0.8323\n",
      "Epoch 9/100\n",
      "418/441 [===========================>..] - ETA: 0s - loss: 0.4380 - accuracy: 0.8304\n",
      "Epoch 9: val_loss did not improve from 0.43553\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8300 - val_loss: 0.4369 - val_accuracy: 0.8307\n",
      "Epoch 10/100\n",
      "425/441 [===========================>..] - ETA: 0s - loss: 0.4373 - accuracy: 0.8309\n",
      "Epoch 10: val_loss improved from 0.43553 to 0.43487, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.8309 - val_loss: 0.4349 - val_accuracy: 0.8320\n",
      "Epoch 11/100\n",
      "416/441 [===========================>..] - ETA: 0s - loss: 0.4379 - accuracy: 0.8314\n",
      "Epoch 11: val_loss improved from 0.43487 to 0.43419, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.8318 - val_loss: 0.4342 - val_accuracy: 0.8323\n",
      "Epoch 12/100\n",
      "411/441 [==========================>...] - ETA: 0s - loss: 0.4353 - accuracy: 0.8295\n",
      "Epoch 12: val_loss improved from 0.43419 to 0.43236, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.8305 - val_loss: 0.4324 - val_accuracy: 0.8350\n",
      "Epoch 13/100\n",
      "419/441 [===========================>..] - ETA: 0s - loss: 0.4350 - accuracy: 0.8307\n",
      "Epoch 13: val_loss did not improve from 0.43236\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8307 - val_loss: 0.4338 - val_accuracy: 0.8327\n",
      "Epoch 14/100\n",
      "426/441 [===========================>..] - ETA: 0s - loss: 0.4356 - accuracy: 0.8305\n",
      "Epoch 14: val_loss did not improve from 0.43236\n",
      "441/441 [==============================] - 0s 998us/step - loss: 0.4352 - accuracy: 0.8310 - val_loss: 0.4324 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "402/441 [==========================>...] - ETA: 0s - loss: 0.4335 - accuracy: 0.8320\n",
      "Epoch 15: val_loss improved from 0.43236 to 0.43170, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8315 - val_loss: 0.4317 - val_accuracy: 0.8350\n",
      "Epoch 16/100\n",
      "392/441 [=========================>....] - ETA: 0s - loss: 0.4344 - accuracy: 0.8319\n",
      "Epoch 16: val_loss did not improve from 0.43170\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.8318 - val_loss: 0.4339 - val_accuracy: 0.8317\n",
      "Epoch 17/100\n",
      "423/441 [===========================>..] - ETA: 0s - loss: 0.4327 - accuracy: 0.8317\n",
      "Epoch 17: val_loss did not improve from 0.43170\n",
      "441/441 [==============================] - 0s 996us/step - loss: 0.4334 - accuracy: 0.8313 - val_loss: 0.4319 - val_accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "420/441 [===========================>..] - ETA: 0s - loss: 0.4334 - accuracy: 0.8322\n",
      "Epoch 18: val_loss did not improve from 0.43170\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8323 - val_loss: 0.4344 - val_accuracy: 0.8320\n",
      "Epoch 19/100\n",
      "422/441 [===========================>..] - ETA: 0s - loss: 0.4334 - accuracy: 0.8321\n",
      "Epoch 19: val_loss improved from 0.43170 to 0.43122, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4337 - accuracy: 0.8318 - val_loss: 0.4312 - val_accuracy: 0.8350\n",
      "Epoch 20/100\n",
      "420/441 [===========================>..] - ETA: 0s - loss: 0.4321 - accuracy: 0.8321\n",
      "Epoch 20: val_loss did not improve from 0.43122\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.8323 - val_loss: 0.4319 - val_accuracy: 0.8337\n",
      "Epoch 21/100\n",
      "427/441 [============================>.] - ETA: 0s - loss: 0.4321 - accuracy: 0.8323\n",
      "Epoch 21: val_loss did not improve from 0.43122\n",
      "441/441 [==============================] - 0s 993us/step - loss: 0.4329 - accuracy: 0.8318 - val_loss: 0.4331 - val_accuracy: 0.8327\n",
      "Epoch 22/100\n",
      "396/441 [=========================>....] - ETA: 0s - loss: 0.4336 - accuracy: 0.8312\n",
      "Epoch 22: val_loss improved from 0.43122 to 0.42974, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8319 - val_loss: 0.4297 - val_accuracy: 0.8356\n",
      "Epoch 23/100\n",
      "422/441 [===========================>..] - ETA: 0s - loss: 0.4332 - accuracy: 0.8322\n",
      "Epoch 23: val_loss improved from 0.42974 to 0.42965, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8323 - val_loss: 0.4296 - val_accuracy: 0.8356\n",
      "Epoch 24/100\n",
      "428/441 [============================>.] - ETA: 0s - loss: 0.4313 - accuracy: 0.8327\n",
      "Epoch 24: val_loss did not improve from 0.42965\n",
      "441/441 [==============================] - 0s 993us/step - loss: 0.4305 - accuracy: 0.8332 - val_loss: 0.4309 - val_accuracy: 0.8353\n",
      "Epoch 25/100\n",
      "430/441 [============================>.] - ETA: 0s - loss: 0.4324 - accuracy: 0.8320\n",
      "Epoch 25: val_loss did not improve from 0.42965\n",
      "441/441 [==============================] - 0s 983us/step - loss: 0.4331 - accuracy: 0.8318 - val_loss: 0.4313 - val_accuracy: 0.8337\n",
      "Epoch 26/100\n",
      "430/441 [============================>.] - ETA: 0s - loss: 0.4310 - accuracy: 0.8336\n",
      "Epoch 26: val_loss improved from 0.42965 to 0.42960, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.8327 - val_loss: 0.4296 - val_accuracy: 0.8366\n",
      "Epoch 27/100\n",
      "398/441 [==========================>...] - ETA: 0s - loss: 0.4292 - accuracy: 0.8346\n",
      "Epoch 27: val_loss improved from 0.42960 to 0.42904, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8329 - val_loss: 0.4290 - val_accuracy: 0.8363\n",
      "Epoch 28/100\n",
      "403/441 [==========================>...] - ETA: 0s - loss: 0.4310 - accuracy: 0.8337\n",
      "Epoch 28: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.8326 - val_loss: 0.4321 - val_accuracy: 0.8323\n",
      "Epoch 29/100\n",
      "429/441 [============================>.] - ETA: 0s - loss: 0.4338 - accuracy: 0.8319\n",
      "Epoch 29: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 994us/step - loss: 0.4322 - accuracy: 0.8327 - val_loss: 0.4313 - val_accuracy: 0.8323\n",
      "Epoch 30/100\n",
      "428/441 [============================>.] - ETA: 0s - loss: 0.4341 - accuracy: 0.8321\n",
      "Epoch 30: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 992us/step - loss: 0.4337 - accuracy: 0.8323 - val_loss: 0.4327 - val_accuracy: 0.8330\n",
      "Epoch 31/100\n",
      "430/441 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.8328\n",
      "Epoch 31: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 983us/step - loss: 0.4310 - accuracy: 0.8331 - val_loss: 0.4325 - val_accuracy: 0.8330\n",
      "Epoch 32/100\n",
      "430/441 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8328\n",
      "Epoch 32: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 982us/step - loss: 0.4306 - accuracy: 0.8321 - val_loss: 0.4297 - val_accuracy: 0.8350\n",
      "Epoch 33/100\n",
      "407/441 [==========================>...] - ETA: 0s - loss: 0.4315 - accuracy: 0.8318\n",
      "Epoch 33: val_loss did not improve from 0.42904\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.8329 - val_loss: 0.4293 - val_accuracy: 0.8327\n",
      "Epoch 34/100\n",
      "408/441 [==========================>...] - ETA: 0s - loss: 0.4312 - accuracy: 0.8318\n",
      "Epoch 34: val_loss improved from 0.42904 to 0.42878, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8327 - val_loss: 0.4288 - val_accuracy: 0.8340\n",
      "Epoch 35/100\n",
      "428/441 [============================>.] - ETA: 0s - loss: 0.4315 - accuracy: 0.8329\n",
      "Epoch 35: val_loss did not improve from 0.42878\n",
      "441/441 [==============================] - 0s 995us/step - loss: 0.4315 - accuracy: 0.8330 - val_loss: 0.4296 - val_accuracy: 0.8356\n",
      "Epoch 36/100\n",
      "413/441 [===========================>..] - ETA: 0s - loss: 0.4284 - accuracy: 0.8342\n",
      "Epoch 36: val_loss improved from 0.42878 to 0.42877, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8333 - val_loss: 0.4288 - val_accuracy: 0.8356\n",
      "Epoch 37/100\n",
      "426/441 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.8341\n",
      "Epoch 37: val_loss improved from 0.42877 to 0.42796, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.8341 - val_loss: 0.4280 - val_accuracy: 0.8363\n",
      "Epoch 38/100\n",
      "428/441 [============================>.] - ETA: 0s - loss: 0.4300 - accuracy: 0.8338\n",
      "Epoch 38: val_loss did not improve from 0.42796\n",
      "441/441 [==============================] - 0s 997us/step - loss: 0.4304 - accuracy: 0.8335 - val_loss: 0.4287 - val_accuracy: 0.8353\n",
      "Epoch 39/100\n",
      "408/441 [==========================>...] - ETA: 0s - loss: 0.4335 - accuracy: 0.8312\n",
      "Epoch 39: val_loss did not improve from 0.42796\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8326 - val_loss: 0.4319 - val_accuracy: 0.8350\n",
      "Epoch 40/100\n",
      "411/441 [==========================>...] - ETA: 0s - loss: 0.4296 - accuracy: 0.8332\n",
      "Epoch 40: val_loss did not improve from 0.42796\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8331 - val_loss: 0.4306 - val_accuracy: 0.8363\n",
      "Epoch 41/100\n",
      "438/441 [============================>.] - ETA: 0s - loss: 0.4289 - accuracy: 0.8335\n",
      "Epoch 41: val_loss improved from 0.42796 to 0.42761, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8333 - val_loss: 0.4276 - val_accuracy: 0.8356\n",
      "Epoch 42/100\n",
      "426/441 [===========================>..] - ETA: 0s - loss: 0.4294 - accuracy: 0.8334\n",
      "Epoch 42: val_loss did not improve from 0.42761\n",
      "441/441 [==============================] - 0s 992us/step - loss: 0.4284 - accuracy: 0.8340 - val_loss: 0.4291 - val_accuracy: 0.8353\n",
      "Epoch 43/100\n",
      "436/441 [============================>.] - ETA: 0s - loss: 0.4292 - accuracy: 0.8331\n",
      "Epoch 43: val_loss did not improve from 0.42761\n",
      "441/441 [==============================] - 0s 979us/step - loss: 0.4298 - accuracy: 0.8329 - val_loss: 0.4281 - val_accuracy: 0.8353\n",
      "Epoch 44/100\n",
      "431/441 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8327\n",
      "Epoch 44: val_loss did not improve from 0.42761\n",
      "441/441 [==============================] - 0s 987us/step - loss: 0.4305 - accuracy: 0.8332 - val_loss: 0.4293 - val_accuracy: 0.8343\n",
      "Epoch 45/100\n",
      "407/441 [==========================>...] - ETA: 0s - loss: 0.4278 - accuracy: 0.8338\n",
      "Epoch 45: val_loss did not improve from 0.42761\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8329 - val_loss: 0.4289 - val_accuracy: 0.8373\n",
      "Epoch 46/100\n",
      "435/441 [============================>.] - ETA: 0s - loss: 0.4291 - accuracy: 0.8337\n",
      "Epoch 46: val_loss improved from 0.42761 to 0.42756, saving model to best_model.h5\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.8340 - val_loss: 0.4276 - val_accuracy: 0.8363\n",
      "Epoch 47/100\n",
      "431/441 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.8328\n",
      "Epoch 47: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 0s 987us/step - loss: 0.4302 - accuracy: 0.8331 - val_loss: 0.4279 - val_accuracy: 0.8347\n",
      "Epoch 48/100\n",
      "436/441 [============================>.] - ETA: 0s - loss: 0.4295 - accuracy: 0.8331\n",
      "Epoch 48: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 0s 974us/step - loss: 0.4287 - accuracy: 0.8337 - val_loss: 0.4306 - val_accuracy: 0.8340\n",
      "Epoch 49/100\n",
      "430/441 [============================>.] - ETA: 0s - loss: 0.4288 - accuracy: 0.8332\n",
      "Epoch 49: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 0s 988us/step - loss: 0.4288 - accuracy: 0.8335 - val_loss: 0.4291 - val_accuracy: 0.8360\n",
      "Epoch 50/100\n",
      "431/441 [============================>.] - ETA: 0s - loss: 0.4296 - accuracy: 0.8332\n",
      "Epoch 50: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 0s 993us/step - loss: 0.4297 - accuracy: 0.8333 - val_loss: 0.4276 - val_accuracy: 0.8360\n",
      "Epoch 51/100\n",
      "410/441 [==========================>...] - ETA: 0s - loss: 0.4309 - accuracy: 0.8325\n",
      "Epoch 51: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4290 - accuracy: 0.8337 - val_loss: 0.4282 - val_accuracy: 0.8356\n",
      "Epoch 52/100\n",
      "395/441 [=========================>....] - ETA: 0s - loss: 0.4288 - accuracy: 0.8343\n",
      "Epoch 52: val_loss did not improve from 0.42756\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4301 - accuracy: 0.8332 - val_loss: 0.4279 - val_accuracy: 0.8363\n",
      "Epoch 53/100\n",
      "424/441 [===========================>..] - ETA: 0s - loss: 0.4270 - accuracy: 0.8342\n",
      "Epoch 53: val_loss improved from 0.42756 to 0.42737, saving model to best_model.h5\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4282 - accuracy: 0.8338 - val_loss: 0.4274 - val_accuracy: 0.8363\n",
      "Epoch 54/100\n",
      "400/441 [==========================>...] - ETA: 0s - loss: 0.4295 - accuracy: 0.8328\n",
      "Epoch 54: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4285 - accuracy: 0.8337 - val_loss: 0.4277 - val_accuracy: 0.8350\n",
      "Epoch 55/100\n",
      "429/441 [============================>.] - ETA: 0s - loss: 0.4282 - accuracy: 0.8335\n",
      "Epoch 55: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8335 - val_loss: 0.4281 - val_accuracy: 0.8327\n",
      "Epoch 56/100\n",
      "429/441 [============================>.] - ETA: 0s - loss: 0.4294 - accuracy: 0.8332\n",
      "Epoch 56: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8334 - val_loss: 0.4276 - val_accuracy: 0.8356\n",
      "Epoch 57/100\n",
      "436/441 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8348\n",
      "Epoch 57: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8340 - val_loss: 0.4285 - val_accuracy: 0.8353\n",
      "Epoch 58/100\n",
      "435/441 [============================>.] - ETA: 0s - loss: 0.4295 - accuracy: 0.8330\n",
      "Epoch 58: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8333 - val_loss: 0.4289 - val_accuracy: 0.8356\n",
      "Epoch 59/100\n",
      "437/441 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8329\n",
      "Epoch 59: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8330 - val_loss: 0.4297 - val_accuracy: 0.8327\n",
      "Epoch 60/100\n",
      "440/441 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8333\n",
      "Epoch 60: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.8335 - val_loss: 0.4293 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "433/441 [============================>.] - ETA: 0s - loss: 0.4276 - accuracy: 0.8341\n",
      "Epoch 61: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8335 - val_loss: 0.4293 - val_accuracy: 0.8353\n",
      "Epoch 62/100\n",
      "440/441 [============================>.] - ETA: 0s - loss: 0.4275 - accuracy: 0.8341\n",
      "Epoch 62: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4275 - accuracy: 0.8340 - val_loss: 0.4284 - val_accuracy: 0.8327\n",
      "Epoch 63/100\n",
      "404/441 [==========================>...] - ETA: 0s - loss: 0.4260 - accuracy: 0.8345\n",
      "Epoch 63: val_loss did not improve from 0.42737\n",
      "441/441 [==============================] - 1s 1ms/step - loss: 0.4275 - accuracy: 0.8336 - val_loss: 0.4302 - val_accuracy: 0.8330\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_denoised, Y_train, epochs=100, batch_size=32, validation_data=(X_val_denoised, Y_val), callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 683us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "Y_pred = best_model.predict(X_test_denoised)\n",
    "Y_pred = (Y_pred > 0.5).astype(int)  # Adjust the threshold for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      2499\n",
      "           1       1.00      0.10      0.17       525\n",
      "\n",
      "    accuracy                           0.84      3024\n",
      "   macro avg       0.92      0.55      0.54      3024\n",
      "weighted avg       0.87      0.84      0.78      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
